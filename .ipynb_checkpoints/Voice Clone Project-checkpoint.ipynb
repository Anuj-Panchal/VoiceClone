{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5653e217",
   "metadata": {},
   "source": [
    "## Code for Voice Clone AI Project\n",
    "### It uses a pre-trained text to speech model with multi speaker support for voice cloning\n",
    "`Can be used with audio sample of around a minute`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70b24d",
   "metadata": {},
   "source": [
    "- ### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7eea93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfca9c2",
   "metadata": {},
   "source": [
    "- ### User Input\n",
    "> The audio text to be synthesized, speed, emotion, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b147cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter the Output speech string to be generatedIdentity and Access Management (IAM) is a set of processes, policies, and tools for controlling user access to critical information within an organization. The enterprise needs IAM to support security and compliance, as well as improve organizational productivity. This applies not only to people resources, but to any entity to which an identity is assigned (e.g., Internet of Things (IoT) devices, application programming interfaces (APIs)). The proliferation of device types and locations from which applications and data are accessed also underlies the importance of identity and access management. Identity and access management reduces the number of traditional points of security failure associated with passwords. The enterprise is vulnerable not only to data breaches associated with passwords and password recovery information, but to human frailties when it comes to creating passwords â€“ generating easy-to-remember (and easy to crack) passwords, using the same passwords across multiple applications and systems, and updating passwords with one minor change instead of completely new, randomly generated passwords. \n",
      "Please Enter the speed of the audio output1\n",
      "Please Enter the type of emotion in the output. Enter 'Neutral' for defaultNeutral\n",
      "Please Enter the output file nameGeneratedOutput\n"
     ]
    }
   ],
   "source": [
    "outputString = input(\"Please Enter the Output speech string to be generated\")\n",
    "outputSpeed = float(input(\"Please Enter the speed of the audio output\"))\n",
    "outputEmotion = input(\"Please Enter the type of emotion in the output. Enter 'Neutral' for default\")\n",
    "outputFileName = input(\"Please Enter the output file name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891aadaa",
   "metadata": {},
   "source": [
    "- ### Loading the pre-trained model\n",
    "\n",
    "    In this case used YourTTS model which is based on [Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech](https://arxiv.org/pdf/2106.06103.pdf)\n",
    "    Other models that can be used are [TortoiseTTS](https://github.com/neonbjb/tortoise-tts) and [Bark](https://github.com/suno-ai/bark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9754cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/your_tts is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n"
     ]
    }
   ],
   "source": [
    "modelName = \"tts_models/multilingual/multi-dataset/your_tts\"\n",
    "ttsModel = TTS(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215de8a",
   "metadata": {},
   "source": [
    "- ### Place the input audio file for cloning in input/ folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffd0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
